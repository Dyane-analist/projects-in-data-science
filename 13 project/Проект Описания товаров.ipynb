{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f40086",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd9e3d",
   "metadata": {},
   "source": [
    "**Цель проекта**\n",
    "\n",
    "Подготовить прототип модели машинного обучения для интернет-магазина «Викишоп», запускающего новый сервис по редактированию и дополнению описаний товаров пользователями, как в вики-сообществах. Модель должна  классифицировать комментарии на позитивные и негативные, чтобы отправлять негативные комментарии на модерацию. \n",
    "\n",
    "При определении оптимальной модели должен быть учтен важный для заказчика параметр:\n",
    "качество предсказания, оцененное метрикой качества F1, должно быть не меньше 0.75.\n",
    "\n",
    "**Данные для анализа**\n",
    "\n",
    "На анализ передан набор данных с разметкой о токсичности правок.\n",
    "\n",
    "**Шаги (план) проекта**\n",
    "\n",
    "1.  Подготовка данных\n",
    "2.  Обучение и проверка моделей на обучающей выборке\n",
    "3.  Проверка модели на тестовой выборке и итоговый вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe97d4",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b609fbd",
   "metadata": {},
   "source": [
    "Импортируем библиотеки, необходимые для работы с данными в текущем проекте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a521550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Maris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Maris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# импорт библиотек\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# предобработка текста\n",
    "from nltk.corpus import stopwords \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stopwords = stopwords.words('english')\n",
    "import re \n",
    "\n",
    "# векторизация текста\n",
    "import torch\n",
    "import transformers as ppb\n",
    "\n",
    "# борьба с дисбалансом\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# обучение моделей\n",
    "import lightgbm as ltb\n",
    "from lightgbm import LGBMClassifier\n",
    "from numpy.random import RandomState\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# оценка качества модели\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# отключение предупреждений\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641a5a9a",
   "metadata": {},
   "source": [
    "Установим RandomState равным 12345."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f49c712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# фиксирование RandomState\n",
    "state = np.random.RandomState(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2776ee5",
   "metadata": {},
   "source": [
    "### Загрузка и изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c8019",
   "metadata": {},
   "source": [
    "Откроем датасет с данными и изучим его. C:\\Users\\Maris\\Desktop\\Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e30b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# открытие файла с применением конструкции try/except для исключения проблем с отработкой кода при подготовке проекта локально\n",
    "try:\n",
    "    df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('C:/Users/Maris/Desktop/Обучение/toxic_comments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c206cf0",
   "metadata": {},
   "source": [
    "Изучим общую информацию о данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6cd939",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# получение общей информации о структуре датафрейма\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af7f45",
   "metadata": {},
   "source": [
    "1. В датасете содержится 159571 строк, 2 столбца.\n",
    "2. Колонки названы в соответствии с правилами нотации Python (латиница, нижний регистр), переименование не требуется.\n",
    "3. В колонке toxic требуется изменение типа данных int64 на int32 для экономии памяти.\n",
    "4. Пропущенных значений нет, обработка пропусков не требуется.\n",
    "5. Требуется проверка данных на наличие явных дубликатов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4b4828",
   "metadata": {},
   "source": [
    "Изменим тип данных в колонке toxic с int64 на int32 для экономии памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3e010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изменение типов данных\n",
    "df[df.select_dtypes(np.int64).columns] = df.select_dtypes(np.int64).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4448961d",
   "metadata": {},
   "source": [
    "Проверим результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8702573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# получение общей информации о структуре датафрейма\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce703007",
   "metadata": {},
   "source": [
    "Изменение типов данных произведено корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f76f73",
   "metadata": {},
   "source": [
    "Проверим датафрейм на наличие явных дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2be3d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка наличия явных дубликатов\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441bb64",
   "metadata": {},
   "source": [
    "Дубликатов нет, удаление не требуется."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14632f2",
   "metadata": {},
   "source": [
    "### Подготовка данных для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4447e79a",
   "metadata": {},
   "source": [
    "**Предобработка текстов**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782666a9",
   "metadata": {},
   "source": [
    "Прежде, чем векторизировать тексты, проведем их предобработку: приведем все тексты к нижнему регистру, удалим небуквенные символы и стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed63bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# перевод всех букв текстов корпуса в нижний регистр\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74c99c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовка функции для удаления символов из текстов (кроме букв)\n",
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clear_text = \" \".join(text.split())\n",
    "    return clear_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "747c4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# очистка текстов от символов (кроме букв)\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: clear_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3ebc21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление стоп-слов из текстов корпуса\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "df[\"text\"] = df[\"text\"].str.replace(pat, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee11bc1",
   "metadata": {},
   "source": [
    "Оценим результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb3576b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation   edits made   username hardcore m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww  matches  background colour   seemingly s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man   really  trying  edit war      guy  c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make  real suggestions  improvement  wonde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir   hero  chance  remember  page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation   edits made   username hardcore m...      0\n",
       "1   aww  matches  background colour   seemingly s...      0\n",
       "2  hey man   really  trying  edit war      guy  c...      0\n",
       "3      make  real suggestions  improvement  wonde...      0\n",
       "4              sir   hero  chance  remember  page         0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод первых 5 строк датафрейма\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53c568",
   "metadata": {},
   "source": [
    "Предобразование текстов проведено успешно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee24e81",
   "metadata": {},
   "source": [
    "**Векторизация текстов**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5465d37",
   "metadata": {},
   "source": [
    "Воспользуемся предобученной моделью DistilBERT для векторизации текстов. Обрежем выборку с учетом ограничений используемой модели векторизации (длина последовательности токенов не более 512)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38280102",
   "metadata": {},
   "source": [
    "Для оптимизации работы и во избежание проблем с нехваткой памяти сократим объем выборки до 2 000 случайных записей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e5258f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# выбор 2 000 случайных текстов из выборки\n",
    "df_sample = df.sample(2000, random_state = 12345).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6363f10e",
   "metadata": {},
   "source": [
    " Загрузим предобученную модель DistilBERT и токенизатор. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b3baf95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# загрузка предобученной модели DistilBert с токенайзером\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e0ce6",
   "metadata": {},
   "source": [
    "Осуществим токенизацию текстов в корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c123206c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [101, 6289, 2232, 3844, 6616, 2079, 19140, 160...\n",
       "1    [101, 7514, 2518, 3146, 6236, 2924, 3190, 1065...\n",
       "2    [101, 7514, 4931, 2071, 2560, 5254, 18626, 134...\n",
       "3            [101, 2008, 2015, 2986, 15117, 9610, 102]\n",
       "4    [101, 1040, 15922, 6488, 2442, 5400, 5638, 221...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замена каждого токена его идентификатором из таблицы эмбеддингов\n",
    "tokenized = df_sample['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True)))\n",
    "tokenized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439254eb",
   "metadata": {},
   "source": [
    "Проверим выполнение условия по максимальной длине последовательности токенов для модели DistilBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7992aece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод длины максимально длинной последовательности токенов в корпусе\n",
    "n = len(max(tokenized, key=len))\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a2e4a",
   "metadata": {},
   "source": [
    "Приведем векторы к одной длине, дополнив их нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe47a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# приведение векторов к одному размеру путем прибавления к более коротким векторам идентификатора 0\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee40af",
   "metadata": {},
   "source": [
    "Сформируем маску для того, чтобы выделить действительно важные токены (укажем нулевые и не нулевые значения)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "448ff8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd8dae",
   "metadata": {},
   "source": [
    "Создадим входной вектор из матрицы токенов и передадим его модели DistilBERT. Сформируем эмбеддинги, для оптимизации памяти разбив корпус на батчи, и сформируем массив признаков из эмбеддингов всех текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fb71b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение эмбеддингов текстов корпуса\n",
    "batch_size = 100\n",
    "results = []\n",
    "for i in range(padded.shape[0] // batch_size):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        mask = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=mask)\n",
    "\n",
    "        results.append(batch_embeddings[0][:,0,:].numpy())\n",
    "\n",
    "features = np.concatenate(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd679c4",
   "metadata": {},
   "source": [
    "Оценим размер получившегося массива."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca2edc37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод размеров массива\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828c5e6",
   "metadata": {},
   "source": [
    "**Подготовка тестовой, валидационной и обучающей выборок**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e58cb",
   "metadata": {},
   "source": [
    "Выделим целевой признак из выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27caccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделение целевого признака - тональности комментария\n",
    "labels = df_sample['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def005fc",
   "metadata": {},
   "source": [
    "Оценим размер получившегося датафрейма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdc70001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод размеров датафрейма\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1755221",
   "metadata": {},
   "source": [
    "Проверим сбалансированность классов в выборке с целевым признаком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62b87df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.904\n",
       "1    0.096\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# расчет процентного соотношения классов\n",
    "labels.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb44d1",
   "metadata": {},
   "source": [
    "Выборка несбалансирована: негативных комментариев в 10 раз больше. Это потребуется учесть при дальнейшем обучении, применив порог классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aeee66",
   "metadata": {},
   "source": [
    "Разделим выборку на обучающую, валидационную и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e07c1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение выборки на обучающую и 20% для валидационной и тестовой выборок\n",
    "features_train, features_tv, target_train, target_tv = train_test_split(\n",
    "    features, labels, test_size=0.20, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccafe175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделение отобранных 20% на валидационную и тестовую выборки\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_tv, target_tv, test_size=0.50, random_state=state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b390a7",
   "metadata": {},
   "source": [
    "Оценим размеры получившихся выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ada6d02a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод размера выборки\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83b12a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод размера выборки\n",
    "features_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bc1d611",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод размера выборки\n",
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f709c622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод размера выборки\n",
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efeecdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод размера выборки\n",
    "target_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c346495d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывод размера выборки\n",
    "target_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118d257",
   "metadata": {},
   "source": [
    "Разделение на выборки прошло корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf70148",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "    \n",
    "**Вывод** \n",
    "\n",
    "В рамках данного этапа были проделаны следующие работы:\n",
    "    \n",
    "1. Открыт файл с данными и проведен их анализ (на вход поступила выборка из 159571 строки, 2 столбцов), по его итогам  изменен тип данных в колонке toxic для экономии памяти; пропусков и дублей в данных не обнаружено.\n",
    "2. Проведена предобработка текстов в корпусе: все буквы приведены к нижнему регистру, из текстов удалены все прочие символы (кроме букв), а также стоп-слова.\n",
    "3. Проведена векторизация текстов с учетом ограничений модели DistilBERT: последовательности токенов обрезаны до 512. С учетом ограничений по оперативной памяти компьютера корпус для дальнейшей работы сокращен до 2000 векторов.\n",
    "4. Проведено разделение признаков и целевого признака на обучающую, валидационную и тестовую выборки (валидационная и тестовая выборки по 10%).\n",
    "5. Выборка сильно несбалансирована по классам (90% - негативная тональность, 10% - позитивная тональность), что потребуется учесть при обучении модели.\n",
    "      \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95470725",
   "metadata": {},
   "source": [
    "## Обучение и проверка моделей на обучающей выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791a154",
   "metadata": {},
   "source": [
    "Обучим и протестируем на обучающей выборке модели **Логистическая регрессия, Случайный лес и LGBM.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9732d",
   "metadata": {},
   "source": [
    "**Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d41cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание модели\n",
    "model_reg = LogisticRegression(random_state=state, solver='liblinear', class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afda3d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание оценщика на основе f1_score\n",
    "f1_scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7378102",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия_F1-score на обучающей выборке: 0.5844264821274946\n"
     ]
    }
   ],
   "source": [
    "# обучение модели и оценка F1-score на обучающей выборке с помощью кросс-валидации\n",
    "result_train_reg = cross_val_score (model_reg, features_train, target_train, cv=5, scoring=f1_scorer).mean()\n",
    "print(\"Логистическая регрессия_F1-score на обучающей выборке:\", result_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db451689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия_F1-score на обучающей выборке с учетом порога: 0.8963210702341137\n"
     ]
    }
   ],
   "source": [
    "# обучение модели и оценка F1-score на обучающей выборке с учетом порога классификации\n",
    "model_reg.fit(features_train, target_train)\n",
    "THRESHOLD = 0.75\n",
    "predictions = np.where(model_reg.predict_proba(features_train)[:,1] > THRESHOLD, 1, 0)\n",
    "print(\"Логистическая регрессия_F1-score на обучающей выборке с учетом порога:\", f1_score(target_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f7dd3",
   "metadata": {},
   "source": [
    "Проверим работу модели также и на валидационной выборке с учетом порога классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8025e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия_F1-score на валидационной выборке с учетом порога: 0.7999999999999999\n"
     ]
    }
   ],
   "source": [
    "# оценка F1-score на валидационной выборке с учетом порога классификации\n",
    "THRESHOLD = 0.75\n",
    "predictions = np.where(model_reg.predict_proba(features_valid)[:,1] > THRESHOLD, 1, 0)\n",
    "print(\"Логистическая регрессия_F1-score на валидационной выборке с учетом порога:\", f1_score(target_valid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ace2a",
   "metadata": {},
   "source": [
    "**Случайный лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "627ce795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'n_estimators': 10}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подбор параметров модели с помощью GridSearchCV\n",
    "clf = RandomForestClassifier(random_state=state)\n",
    "parameters = {'n_estimators': range (10, 51, 10),\n",
    "              'max_depth': range (1,13,2)}\n",
    "grid = GridSearchCV(clf, parameters, cv=5, scoring=f1_score, n_jobs=-1)\n",
    "grid.fit(features_train, target_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d036a21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# сознание модели\n",
    "model_forest = RandomForestClassifier(random_state=state, max_depth=1, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acc51f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес_F1-score на обучающей выборке: 0.0\n"
     ]
    }
   ],
   "source": [
    "# обучение модели и оценка F1-score на обучающей выборке с помощью кросс-валидации\n",
    "result_train_forest = cross_val_score (model_forest, features_train, target_train, cv=5, scoring=f1_scorer).mean()\n",
    "print(\"Случайный лес_F1-score на обучающей выборке:\", result_train_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60deb3eb",
   "metadata": {},
   "source": [
    "**LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99ffdb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'n_estimators': 50}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подбор параметров с помощью GridSearchCV\n",
    "clf = ltb.LGBMClassifier(random_state=state)\n",
    "parameters = {\n",
    "    'max_depth': [5, 9],\n",
    "    'n_estimators': [50, 100],\n",
    "}\n",
    "grid = GridSearchCV(clf, parameters, cv=5, scoring=f1_score, n_jobs=-1)\n",
    "grid.fit(features_train, target_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfe52816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сознание модели\n",
    "model_LGBM = ltb.LGBMClassifier(random_state=state, max_depth=5, n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1745e0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM_F1-score на обучающей выборке: 0.4947937181235167\n"
     ]
    }
   ],
   "source": [
    "# обучение модели и оценка F1-score на обучающей выборке с помощью кросс-валидации\n",
    "result_train_LGBM = cross_val_score (model_LGBM, features_train, target_train, cv=5, scoring=f1_scorer).mean()\n",
    "print(\"LGBM_F1-score на обучающей выборке:\", result_train_LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd53e32",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "    \n",
    "**Вывод** \n",
    "\n",
    "В рамках данного этапа были проделаны следующие работы:\n",
    "1. На данных обучающей выборки проведено обучение моделей Логистической регрессии, Случайного леса и LGBM. Результаты приведены в таблице:\n",
    "    \n",
    "|Модель                                   |Качество предсказания (F1 score)|\n",
    "|:---------------------------------------:|-------------------------------:|\n",
    "|Логистическая регрессия                  |0.58                            |\n",
    "|Логистическая регрессия с учетом порога  |0.89                            |\n",
    "|Случайный лес max_depth=1, n_est=10      |0.00                            |\n",
    "|LGBM max_depth=5, n_est=50               |0.49                            |  \n",
    "\n",
    "2. Также проведено обучение и проверка модели Логистической регрессии на валидационной выборке. F1-score составил 0.79. \n",
    "    \n",
    "Таким образом, модель Логистической регрессии с учетом порога классификации показала наилучшие результаты, которые мы проверим на следующем шаге на данных тестовой выборки.      \n",
    "   \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707584a6",
   "metadata": {},
   "source": [
    "## Проверка модели на тестовой выборке и итоговый вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838fce3d",
   "metadata": {},
   "source": [
    "По итогам обучения и проверки на обучающей и валидационной выборках наилучший результат показала модель **Логистической регрессии** с учетом порога классификации. Оценим ее результаты на данных тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "173cd7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия_F1-score на тестовой выборке с учетом порога: 0.8372093023255814\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 0.75\n",
    "predictions = np.where(model_reg.predict_proba(features_test)[:,1] > THRESHOLD, 1, 0)\n",
    "print(\"Логистическая регрессия_F1-score на тестовой выборке с учетом порога:\", f1_score(target_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d1247",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\">\n",
    "    \n",
    "**Вывод** \n",
    "\n",
    "В рамках данного этапа проведена проверка результативности модели Логистической регрессии с учетом порога на тестовых данных. Итоговое значение метрики F1 на тестовых данных составило 0.83, что соответствует условию задачи (f1_score не менее 0.75).\n",
    "    \n",
    "Таким образом, данная модель может быть рекомендована для дальнейшего использования сервисом.    \n",
    "   \n",
    "<div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
